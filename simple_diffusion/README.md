# simple_diffusion — Flow Matching Super-Resolution for MHD

Standalone flow matching super-resolution trainer. Takes 2x-downsampled MHD fields as input and learns to generate the high-resolution version conditioned on the low-res input.

## Method

**Flow matching** with linear interpolation paths:
- `x0` = noise (base distribution), `x1` = high-res target
- `xt = (1-t)*x0 + t*x1`, with `t ~ U(0,1)`
- Model predicts the velocity field `v = x1 - x0`
- Loss: `MSE(v_pred, v_true)`
- Sampling: Euler ODE integration from `t=0` to `t=1` (50 steps)

The model is conditioned on the low-res input by channel-concatenation: the UNet receives `cat(xt, x_lo)` (16 channels) and outputs the 8-channel velocity prediction.

## Data

Uses `all_fields_256x256.npy` — shape `(1001, 256, 256, 8)`, channels-last, float32.

8 MHD fields from AthenaK MRI simulations:

| Channel | Field   | Description        |
|---------|---------|--------------------|
| 0       | density | mass density       |
| 1       | velx    | x-velocity         |
| 2       | vely    | y-velocity         |
| 3       | velz    | z-velocity         |
| 4       | Bx      | x magnetic field   |
| 5       | By      | y magnetic field   |
| 6       | Bz      | z magnetic field   |
| 7       | jz      | z current density  |

Low-res inputs are created on-the-fly: `avg_pool2d` to 128x128, then bilinear upsample back to 256x256.

The data is generated by `plotting/convert_to_npy.py` from raw AthenaK binary snapshots.

## Model

UNet adapted from `gf3/models/mg_unet.py` with:

- **Architecture**: Encoder-decoder with skip connections, ResBlock downsampling/upsampling
- **Conditioning**: Fourier time embedding -> MLP -> scale-shift in each ResBlock (FiLM)
- **Channels**: `model_channels=128`, `channel_mult=(1,2,2,2)` -> 128, 256, 256, 256
- **Attention**: Self-attention at 64x64 resolution (ds=4), 4 heads with 64 channels each
- **ResBlocks**: 2 per level, GroupNorm + scale-shift, zero-init output conv
- **Input/Output**: 16 channels in (8 xt + 8 x_lo), 8 channels out (velocity)
- **Parameters**: ~43M

Changes from gf3: configurable channel counts, single time embedding (not two-time), no augmentation conditioning, `forward(t, x)` signature.

## Files

```
simple_diffusion/
  model.py    — UNet definition (ResBlock, AttentionBlock, Fourier embeddings, etc.)
  trainer.py  — Dataset, flow matching training loop, Euler sampling, wandb visualization
  README.md   — this file
```

## Config

Hyperparameters are set at the top of `trainer.py`:

```python
batch_size = 8
lr = 1e-4
total_steps = 50_000
print_every = 100       # print loss to stdout
log_every = 1000        # log sample images to wandb
sample_steps = 50       # Euler ODE steps at inference
base_dist = "gaussian"  # or "x_lo_plus_noise"
```

`base_dist` controls what `x0` is:
- `"gaussian"`: `x0 = N(0, I)` — standard flow matching
- `"x_lo_plus_noise"`: `x0 = x_lo + N(0, I)` — starts closer to the target

## Usage

```bash
source load.sh
python3 simple_diffusion/trainer.py
```

Logs training loss and sample comparison images (velx, Bx) to wandb under project `mri`, run name `flow_matching_sr`. Saves final checkpoint to `simple_diffusion/checkpoint.pt`.

### Wandb visualizations

Every `log_every` steps, generates samples for 4 fixed inputs and logs a 3-row comparison for each visualized channel:
- Row 1: Low-res input
- Row 2: Ground truth high-res
- Row 3: Generated high-res
